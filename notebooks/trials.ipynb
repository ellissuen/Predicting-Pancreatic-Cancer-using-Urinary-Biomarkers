{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b97ddbe3-e5f8-4e75-885d-c4feda70696c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e4de4961-09c3-4526-91e2-7c71a85d59cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from open_file import open_file\n",
    "import data_preprocessing\n",
    "import model_training\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791cc07-c0ff-4fb0-b340-8ccf63168b06",
   "metadata": {},
   "source": [
    "# Pretrial 1:\n",
    "## Simplest model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63465948-4f40-418a-98ce-a0d11e1e76a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = '../data/Debernardi et al 2020 data.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2018811e-6802-4dff-87b0-f2dbafbef721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#choose subset without null values and assign X / y\n",
    "\n",
    "data = df[['age', 'creatinine', 'LYVE1', 'REG1B', 'TFF1', 'diagnosis']]\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c9d52d6b-542f-4e50-b53d-4183f4d3b005",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6186440677966102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.59      0.62        41\n",
      "           2       0.47      0.44      0.45        39\n",
      "           3       0.70      0.84      0.76        38\n",
      "\n",
      "    accuracy                           0.62       118\n",
      "   macro avg       0.61      0.62      0.61       118\n",
      "weighted avg       0.61      0.62      0.61       118\n",
      "\n",
      "[[24 16  1]\n",
      " [ 9 17 13]\n",
      " [ 3  3 32]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.validation import column_or_1d\n",
    "\n",
    "# Step 1: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert y_train and y_test to 1D arrays\n",
    "y_train = column_or_1d(y_train)\n",
    "y_test = column_or_1d(y_test)\n",
    "\n",
    "# Step 2: Instantiate the model and fit\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Step 3: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f09b334-f7be-43bc-a72d-3d9fe33fa3d3",
   "metadata": {},
   "source": [
    "#### My finished model must have an accuracy of better than 61.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf76b26a-ad4c-49f8-b48b-b37732a61478",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pretrial 2:\n",
    "## Change classification task to BINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e7eb5bde-0440-4ef0-bb1b-220736a51b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_diagnosis(value):\n",
    "    if value in [1, 2]:\n",
    "        return 'no cancer'\n",
    "    else:\n",
    "        return 'cancer'\n",
    "\n",
    "# Apply the classification function to each value in the 'diagnosis' column\n",
    "y = y['diagnosis'].apply(classify_diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "abfb120f-cdc5-4737-be4c-12e6ce8af76d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "no cancer    391\n",
       "cancer       199\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "07b5b77e-9289-42c7-9aff-3b9591b143eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7966101694915254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cancer       0.68      0.68      0.68        38\n",
      "   no cancer       0.85      0.85      0.85        80\n",
      "\n",
      "    accuracy                           0.80       118\n",
      "   macro avg       0.77      0.77      0.77       118\n",
      "weighted avg       0.80      0.80      0.80       118\n",
      "\n",
      "[[26 12]\n",
      " [12 68]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Instantiate the model\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Step 3: Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Predict on test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Other evaluation metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fc8b1a-5e91-4f7b-80f1-24e49657f2d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### My finished model must have an accuracy of better than 79.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e38ff4-c947-4a88-9d3b-2d917beb5556",
   "metadata": {},
   "source": [
    "# Pretrial 3:\n",
    "## Model with mean replacement. Increase complexity slightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "987e9e48-cc2f-49e4-b744-34544b82e621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = df[['age', 'plasma_CA19_9', 'creatinine', 'LYVE1', 'REG1B', 'TFF1', 'REG1A', 'diagnosis']]\n",
    "\n",
    "#filled with means\n",
    "\n",
    "# Create a copy of the DataFrame\n",
    "data_copy = data.copy()\n",
    "\n",
    "# Fill missing values in 'plasma_CA19_9' column with its mean\n",
    "data_copy['plasma_CA19_9'].fillna(data_copy['plasma_CA19_9'].mean(), inplace=True)\n",
    "\n",
    "# Fill missing values in 'REG1A' column with its mean\n",
    "data_copy['REG1A'].fillna(data_copy['REG1A'].mean(), inplace=True)\n",
    "\n",
    "def classify_diagnosis(value):\n",
    "    if value in [1, 2]:\n",
    "        return 'no cancer'\n",
    "    else:\n",
    "        return 'cancer'\n",
    "\n",
    "# Apply the classification function to each value in the 'diagnosis' column\n",
    "y = y['diagnosis'].apply(classify_diagnosis)\n",
    "\n",
    "X = data_copy.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "81e2aa7c-e42e-43cf-a2db-ab7444f90d51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8050847457627118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cancer       0.68      0.74      0.71        38\n",
      "   no cancer       0.87      0.84      0.85        80\n",
      "\n",
      "    accuracy                           0.81       118\n",
      "   macro avg       0.78      0.79      0.78       118\n",
      "weighted avg       0.81      0.81      0.81       118\n",
      "\n",
      "[[28 10]\n",
      " [13 67]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Instantiate the model\n",
    "clf = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "# Step 3: Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Predict on test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Other evaluation metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fddc2c-7a79-4c73-916d-853fe34de3c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Simple model has improve drastically from the beginning\n",
    "#### My finished model should have an accuracy better than 80.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3de17a-8fbc-4276-98e8-f399065dea7c",
   "metadata": {},
   "source": [
    "# Trial 1: \n",
    "# Optimize Missing Value Imputation / Scaling\n",
    "\n",
    "Accuracy has been chosen as a quick way to determine these early model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93bae60a-fad0-43f8-8aa1-5dbb8b50d462",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>is_male</th>\n",
       "      <th>plasma_CA19_9</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>LYVE1</th>\n",
       "      <th>REG1B</th>\n",
       "      <th>TFF1</th>\n",
       "      <th>REG1A</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1.83222</td>\n",
       "      <td>0.893219</td>\n",
       "      <td>52.948840</td>\n",
       "      <td>654.282174</td>\n",
       "      <td>1262.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97266</td>\n",
       "      <td>2.037585</td>\n",
       "      <td>94.467030</td>\n",
       "      <td>209.488250</td>\n",
       "      <td>228.407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.78039</td>\n",
       "      <td>0.145589</td>\n",
       "      <td>102.366000</td>\n",
       "      <td>461.141000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.70122</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>60.579000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.21489</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>65.540000</td>\n",
       "      <td>41.088000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.52026</td>\n",
       "      <td>7.058209</td>\n",
       "      <td>156.241000</td>\n",
       "      <td>525.178000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85956</td>\n",
       "      <td>8.341207</td>\n",
       "      <td>16.915000</td>\n",
       "      <td>245.947000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.36851</td>\n",
       "      <td>7.674707</td>\n",
       "      <td>289.701000</td>\n",
       "      <td>537.286000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.33458</td>\n",
       "      <td>8.206777</td>\n",
       "      <td>205.930000</td>\n",
       "      <td>722.523000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>1.50423</td>\n",
       "      <td>8.200958</td>\n",
       "      <td>411.938275</td>\n",
       "      <td>2021.321078</td>\n",
       "      <td>13200.000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  is_male  plasma_CA19_9  creatinine     LYVE1       REG1B  \\\n",
       "0     33        0           11.7     1.83222  0.893219   52.948840   \n",
       "1     81        0            NaN     0.97266  2.037585   94.467030   \n",
       "2     51        1            7.0     0.78039  0.145589  102.366000   \n",
       "3     61        1            8.0     0.70122  0.002805   60.579000   \n",
       "4     62        1            9.0     0.21489  0.000860   65.540000   \n",
       "..   ...      ...            ...         ...       ...         ...   \n",
       "585   68        1            NaN     0.52026  7.058209  156.241000   \n",
       "586   71        0            NaN     0.85956  8.341207   16.915000   \n",
       "587   63        1            NaN     1.36851  7.674707  289.701000   \n",
       "588   75        0            NaN     1.33458  8.206777  205.930000   \n",
       "589   74        1         1488.0     1.50423  8.200958  411.938275   \n",
       "\n",
       "            TFF1      REG1A  diagnosis  \n",
       "0     654.282174   1262.000          1  \n",
       "1     209.488250    228.407          1  \n",
       "2     461.141000        NaN          1  \n",
       "3     142.950000        NaN          1  \n",
       "4      41.088000        NaN          1  \n",
       "..           ...        ...        ...  \n",
       "585   525.178000        NaN          3  \n",
       "586   245.947000        NaN          3  \n",
       "587   537.286000        NaN          3  \n",
       "588   722.523000        NaN          3  \n",
       "589  2021.321078  13200.000          3  \n",
       "\n",
       "[590 rows x 9 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = open_file()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f260f6c6-a223-4b1c-95d7-b603fc6cd348",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Value Imputation: Remove Missing Values\n",
      "Scaling/Normalization: Min-Max Scaling\n",
      "Accuracy: 0.8050847457627118\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Missing Value Imputation: Remove Missing Values\n",
      "Scaling/Normalization: Robust Scaling\n",
      "Accuracy: 0.8050847457627118\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Missing Value Imputation: Remove Missing Values\n",
      "Scaling/Normalization: Quantile Transformation\n",
      "Accuracy: 0.8389830508474576\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Missing Value Imputation: Remove Missing Values\n",
      "Scaling/Normalization: Log Transformation\n",
      "Accuracy: 0.8305084745762712\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Missing Value Imputation: Replace with Mean\n",
      "Scaling/Normalization: Min-Max Scaling\n",
      "Accuracy: 0.8220338983050848\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Missing Value Imputation: Replace with Mean\n",
      "Scaling/Normalization: Robust Scaling\n",
      "Accuracy: 0.8050847457627118\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Missing Value Imputation: Replace with Mean\n",
      "Scaling/Normalization: Quantile Transformation\n",
      "Accuracy: 0.8220338983050848\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Missing Value Imputation: Replace with Mean\n",
      "Scaling/Normalization: Log Transformation\n",
      "Accuracy: 0.8220338983050848\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Missing Value Imputation: Replace with KNN\n",
      "Scaling/Normalization: Min-Max Scaling\n",
      "Accuracy: 0.8220338983050848\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Missing Value Imputation: Replace with KNN\n",
      "Scaling/Normalization: Robust Scaling\n",
      "Accuracy: 0.8220338983050848\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Missing Value Imputation: Replace with KNN\n",
      "Scaling/Normalization: Quantile Transformation\n",
      "Accuracy: 0.864406779661017\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Missing Value Imputation: Replace with KNN\n",
      "Scaling/Normalization: Log Transformation\n",
      "Accuracy: 0.847457627118644\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#iterate over missing value imputations functions\n",
    "#iterate over scaling / normalization functions\n",
    "# using a standard:\n",
    "    # feature selection\n",
    "    # data split\n",
    "    # log reg classifier\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "missing_value_functions = data_preprocessing.missing_value_functions\n",
    "scaling_normalization_functions = data_preprocessing.scaling_normalization_functions\n",
    "feature_selection_functions = data_preprocessing.feature_selection_functions\n",
    "\n",
    "for missing_func, missing_desc in missing_value_functions.items():\n",
    "    imputed_df = missing_func(df)\n",
    "    \n",
    "    X = imputed_df.iloc[:, :-1]\n",
    "    y = imputed_df.iloc[:, -1:]\n",
    "    \n",
    "    def classify_diagnosis(value):\n",
    "        if value in [1, 2]:\n",
    "            return '0'\n",
    "        else:\n",
    "            return '1'\n",
    "\n",
    "    # Apply the classification function to each value in the 'diagnosis' column\n",
    "    y = y['diagnosis'].apply(classify_diagnosis)\n",
    "    \n",
    "    for scaling_func, scaling_desc in scaling_normalization_functions.items():\n",
    "        X_transformed_data = scaling_func(X)\n",
    "        X_transformed_df = pd.DataFrame(X_transformed_data, columns=imputed_df.columns[:-1])\n",
    "        \n",
    "        # Train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_transformed_df, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        logistic_regression = LogisticRegression(max_iter=1000)\n",
    "        logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = logistic_regression.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Missing Value Imputation: {missing_desc}\")\n",
    "        print(f'Scaling/Normalization: {scaling_desc}')\n",
    "\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")  # Add a separator between dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeee0b5-b257-40dd-8389-ca3c60f18f76",
   "metadata": {},
   "source": [
    "## Results:\n",
    "**Best Missing Value Handler**\n",
    "* KNN Imputer\n",
    "* replace with mean also seems robust across different scalers\n",
    "* remove columns seems unstable with different setups\n",
    "\n",
    "**Best Scaler / Normalization**\n",
    "* quantile transformation\n",
    "* log transformation seems pretty good\n",
    "* min max scale / robust scale performed worse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906d385-8850-4a72-8fdb-b5c066177917",
   "metadata": {},
   "source": [
    "# Trial 2:\n",
    "# Optimize Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91dae46a-52e1-41b8-b7e5-20430aa8fa97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#iterate over feature selection methods \n",
    "# using a standard:\n",
    "    # knn replacement\n",
    "    # min max scaler\n",
    "    # train test split\n",
    "    # log reg classifier\n",
    "\n",
    "imputed_df = data_preprocessing.knn_missing(df)\n",
    "\n",
    "X = imputed_df.iloc[:, :-1]\n",
    "y = imputed_df.iloc[:, -1:]\n",
    "\n",
    "y = y['diagnosis'].apply(classify_diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c97ff85-badb-4732-a8df-be428f7280f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_scaled = data_preprocessing.min_max_scaler(X)\n",
    "X_df_scaled = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90101f88-2882-4cc7-be3f-fcc32ed3f0d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for evaluating and printing results\n",
    "def train_logistic_regression(X, y, selected_features):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[selected_features], y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and train the logistic regression model\n",
    "    logistic_regression = LogisticRegression(max_iter=1000)\n",
    "    logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f66c3e6-bc86-4d69-b0c1-4d9757453584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['creatinine', 'LYVE1', 'REG1B', 'TFF1', 'REG1A'], dtype='object')\n",
      "RFE Accuracy: 0.847457627118644\n"
     ]
    }
   ],
   "source": [
    "# Feature selection using RFE\n",
    "selected_features_rfe = data_preprocessing.rfe_feature(X_df_scaled, y, n_features_to_select=5)\n",
    "\n",
    "# Train logistic regression using RFE selected features\n",
    "accuracy_rfe = train_logistic_regression(X_df_scaled, y, selected_features_rfe)\n",
    "print(selected_features_rfe)\n",
    "print(f'RFE Accuracy: {accuracy_rfe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2342f935-29ee-4717-9558-f63e09e95a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature selection using Lasso\n",
    "selected_features_lasso = data_preprocessing.lasso_feature(X_df_scaled, y, alpha=0.003)\n",
    "len(X_df_scaled[selected_features_lasso].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "984d5633-3939-4d1a-a6cc-11f5c207f3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Accuracy: 0.8220338983050848\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression using Lasso selected features\n",
    "accuracy_lasso = train_logistic_regression(X_df_scaled, y, selected_features_lasso)\n",
    "print(f'Lasso Accuracy: {accuracy_lasso}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8559b164-919e-445e-afd0-d5281630336e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Accuracy: 0.8305084745762712\n"
     ]
    }
   ],
   "source": [
    "# Feature selection using PCA\n",
    "pca = data_preprocessing.pca_feature(X_df_scaled, n_components=7)\n",
    "X_pca_transformed = pca.transform(X_df_scaled)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'PCA Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d84c149-ac4d-4e6c-b9b7-0cf2a83846ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results:\n",
    "**Best Missing Value Handler**\n",
    "* RFE\n",
    "\n",
    "**RFE**\n",
    "* 84.7%\n",
    "* 5 features is the best with this setup\n",
    "\n",
    "**Lasso**\n",
    "* 82.2%\n",
    "* (>6) is the best with this setup\n",
    "* alpha < 0.003\n",
    "\n",
    "**PCA**\n",
    "* 83.1%\n",
    "* PC6 - PC 7 best\n",
    "* not viable as PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7633908e-4f34-491f-8d01-2cea18edfb99",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Trial 3:\n",
    "# Optimize Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eb6f0bf-3480-4244-ba5d-99e3ea7e94ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#iterate over data split methods\n",
    "# using a standard:\n",
    "    # knn replacement\n",
    "    # min max scaler\n",
    "    # rfe feature selection of 5\n",
    "    # log reg classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e3323ac-639a-4d28-950e-1a715d34cb75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age  is_male  plasma_CA19_9  creatinine     LYVE1     REG1B  \\\n",
      "0    0.111111      0.0       0.000377    0.437326  0.037383  0.037715   \n",
      "1    0.873016      0.0       0.039329    0.225627  0.085284  0.067288   \n",
      "2    0.396825      1.0       0.000226    0.178273  0.006089  0.072915   \n",
      "3    0.555556      1.0       0.000258    0.158774  0.000112  0.043150   \n",
      "4    0.571429      1.0       0.000290    0.038997  0.000031  0.046684   \n",
      "..        ...      ...            ...         ...       ...       ...   \n",
      "585  0.666667      1.0       0.003497    0.114206  0.295438  0.111290   \n",
      "586  0.714286      0.0       0.062715    0.197772  0.349142  0.012048   \n",
      "587  0.587302      1.0       0.065407    0.323120  0.321244  0.206354   \n",
      "588  0.777778      0.0       0.015365    0.314763  0.343515  0.146684   \n",
      "589  0.761905      1.0       0.048000    0.356546  0.343272  0.293424   \n",
      "\n",
      "         TFF1     REG1A  \n",
      "0    0.049030  0.095606  \n",
      "1    0.015698  0.017304  \n",
      "2    0.034557  0.014277  \n",
      "3    0.010712  0.013531  \n",
      "4    0.003079  0.012124  \n",
      "..        ...       ...  \n",
      "585  0.039356  0.032790  \n",
      "586  0.018430  0.034695  \n",
      "587  0.040263  0.171887  \n",
      "588  0.054144  0.173711  \n",
      "589  0.151474  1.000000  \n",
      "\n",
      "[590 rows x 8 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "585    1\n",
      "586    1\n",
      "587    1\n",
      "588    1\n",
      "589    1\n",
      "Name: diagnosis, Length: 590, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_df_scaled)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b858d82c-0e2d-4d58-a42f-89ae40175964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature selection using RFE\n",
    "selected_features_rfe = data_preprocessing.rfe_feature(X_df_scaled, y, n_features_to_select=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac8cc152-3e7d-4d75-90f0-9d4ce6256e49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Test Split: 0.847457627118644\n",
      "Repeated K Fold Fold 1 Accuracy: 0.847457627118644\n",
      "Repeated K Fold Fold 2 Accuracy: 0.7542372881355932\n",
      "Repeated K Fold Fold 3 Accuracy: 0.8050847457627118\n",
      "Repeated K Fold Fold 4 Accuracy: 0.7288135593220338\n",
      "Repeated K Fold Fold 5 Accuracy: 0.8220338983050848\n",
      "Repeated K Fold Fold 6 Accuracy: 0.8389830508474576\n",
      "Repeated K Fold Fold 7 Accuracy: 0.7711864406779662\n",
      "Repeated K Fold Fold 8 Accuracy: 0.7372881355932204\n",
      "Repeated K Fold Fold 9 Accuracy: 0.7711864406779662\n",
      "Repeated K Fold Fold 10 Accuracy: 0.8050847457627118\n",
      "Average Accuracy across all folds: 0.8050847457627118\n"
     ]
    }
   ],
   "source": [
    "data_splitting_functions = data_preprocessing.data_splitting_functions\n",
    "\n",
    "for split_func, split_desc in data_splitting_functions.items():           \n",
    "    # Check if using Train Test Split\n",
    "    if split_func == data_preprocessing.train_test_datasplit:\n",
    "       \n",
    "        X_train, X_test, y_train, y_test = split_func(X_df_scaled[selected_features_rfe], y, test_size = 0.2)\n",
    "\n",
    "         # Initialize and train the logistic regression model\n",
    "        logistic_regression = LogisticRegression(max_iter=1000)\n",
    "        logistic_regression.fit(X_train, y_train)\n",
    "        y_pred = logistic_regression.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f'Train Test Split: {accuracy}')\n",
    "        \n",
    "    # Else using Repeated K Fold\n",
    "    # n_splits = 5, n_repeats = 2\n",
    "    else: \n",
    "        splits = list(split_func(X_df_scaled[selected_features_rfe], y))\n",
    "        \n",
    "        for fold, (train_index, test_index) in enumerate(splits):\n",
    "            # Split data into train and test sets\n",
    "            X_train, X_test = X_df_scaled[selected_features_rfe].iloc[train_index], X_df_scaled[selected_features_rfe].iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Initialize and train the logistic regression model\n",
    "            logistic_regression = LogisticRegression(max_iter=1000)\n",
    "            logistic_regression.fit(X_train, y_train)\n",
    "            y_pred = logistic_regression.predict(X_test)\n",
    "            fold_accuracy = accuracy_score(y_test, y_pred)\n",
    "            fold_accuracies = []\n",
    "            fold_accuracies.append(fold_accuracy)\n",
    "\n",
    "            print(f'Repeated K Fold Fold {fold+1} Accuracy: {fold_accuracy}')\n",
    "\n",
    "        # Calculate and print average accuracy across all folds\n",
    "        avg_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "        print(f'Average Accuracy across all folds: {avg_accuracy}')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993e7dd3-2442-486d-84c2-75847be42e5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results:\n",
    "**Data Splitting**\n",
    "* Train test split produced better results\n",
    "\n",
    "**Train Test Split**\n",
    "* 84.7%\n",
    "* much less computational resources\n",
    "\n",
    "**Repeated K Fold**\n",
    "* 80.5%\n",
    "* Will continue to experiment, but may not be worth the effort due to increased computational complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a114e997-128b-4f5a-b923-e5ba69c39e34",
   "metadata": {},
   "source": [
    "# Trial 4:\n",
    "# Choose best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6952ee3-4f51-4526-bf96-f1feaeb33c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0601302-cba8-4a64-8056-fbce852dd82f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#iterate over classification models\n",
    "# using a standard:\n",
    "    # knn replacement\n",
    "    # min max scaler\n",
    "    # rfe feature selection of 5\n",
    "    # train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f34b9f89-005c-4519-9cac-02ec101b197f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df_scaled[selected_features_rfe], y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ff8c6fb-8b71-4461-900e-34bbcfb5ab53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Best Hyperparameters: {'max_iter': 100}\n",
      "Accuracy: 0.847457627118644\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Random Forest:\n",
      "Best Hyperparameters: {'max_depth': 5, 'n_estimators': 50}\n",
      "Accuracy: 0.8305084745762712\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Gradient Boosting:\n",
      "Best Hyperparameters: {'learning_rate': 0.01, 'n_estimators': 200}\n",
      "Accuracy: 0.8135593220338984\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Support Vector Machine:\n",
      "Best Hyperparameters: {'C': 1.0, 'kernel': 'rbf'}\n",
      "Accuracy: 0.8389830508474576\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "K-Nearest Neighbors:\n",
      "Best Hyperparameters: {'n_neighbors': 3}\n",
      "Accuracy: 0.788135593220339\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all models\n",
    "for model_func, (param_grid, model_name) in models_params.items():\n",
    "    # Perform Grid Search to find the best hyperparameters\n",
    "    grid_search = GridSearchCV(model_func(X_train, X_test, y_train, y_test), param_grid, cv=3, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best hyperparameters and the corresponding accuracy\n",
    "    best_params = grid_search.best_params_\n",
    "    best_accuracy = grid_search.best_score_\n",
    "    \n",
    "    # Train the model with the best hyperparameters\n",
    "    best_model = model_func(X_train, X_test, y_train, y_test, **best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f'{model_name}:')\n",
    "    print(f'Best Hyperparameters: {best_params}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")  # Add a separator between models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c650a-37c3-4d6f-b4ee-7a3b014a8333",
   "metadata": {},
   "source": [
    "## Results:\n",
    "\n",
    "**Classification Models**\n",
    "\n",
    "**Logistic Regression:**\n",
    "* Best Results\n",
    "\n",
    "**Random Forest:**\n",
    "* Decent Results\n",
    "\n",
    "**Gradient Boosting:**\n",
    "* Decent Results\n",
    "\n",
    "**Support Vector Machine:**\n",
    "* Decent Reults\n",
    "\n",
    "**K-Nearest Neighbors:**\n",
    "* Worst Results\n",
    "\n",
    "**Very general look at the models and will have to be iterated through with other data_preprocessing steps included to find the best outcome**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b62657-752f-4ed9-bfef-eacac098520a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
